# -*- coding: utf-8 -*-
"""CNN Image Classification with dropout.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15PV2yZwWzX0_l4W6uZAR3e5wzJqmizbr
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
# % matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow
print(tensorflow.__version__)

import tensorflow as tf
tf.test.gpu_device_name()

#importing all the necessary packages
#tensorflow 2.0
from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(96, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

model.summary()

model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#Image data Generator
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(zoom_range=0.2, horizontal_flip=True)

# train the model
start = time.time()
# fits the model on batches with real-time data augmentation:
history=model.fit_generator(datagen.flow(train_images, train_labels, batch_size=128),
                    steps_per_epoch=1000, epochs=100,validation_data=(test_images, test_labels))

end = time.time()
print("Model took %0.2f seconds to train"%(end - start))

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive 
from google.colab import auth 
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

model.save('model_CNN.h5')
model_file = drive.CreateFile({'CNN_model' : 'model_CNN.h5'})
model_file.SetContentFile('model_CNN.h5')                      
model_file.Upload()

# always save your weights after training or during training
model.save_weights('C:/Users/RohithRamesh/Desktop/CC Configuration/CNN_100_epochs')

from tensorflow.keras.models import load_model

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

load_model = tf.keras.models.load_model('drive/My Drive/model_CNN.h5')

load_model.summary()

"""**Testing with an image**"""

img_test = tf.keras.preprocessing.image.load_img('drive/My Drive/DATA files/CNN model weights/Horse_image.jpg',
    grayscale=False,
    color_mode='rgb',
    target_size=None,
    interpolation='nearest'
)

img_test

img_test1 = np.array(img_test)

img_test1.shape

img_test2 = tf.keras.preprocessing.image.load_img('drive/My Drive/DATA files/CNN model weights/Horse_image.jpg',
    grayscale=False,
    color_mode='rgb',
    target_size=(32,32))

img = np.array(img_test2)
img.shape

img = img / 255.0

"""**reshape into a single sample with 3 channels**"""

img = img.reshape(1, 32, 32, 3)

"""**predict the class**"""

predictions = load_model.predict_classes(img)

predictions

labels =  ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

result = np.argmax(load_model.predict(img))
print(result)

labels[result]

"""**Test Image 2**"""

image_test= tf.keras.preprocessing.image.load_img('drive/My Drive/DATA files/CNN model weights/Deer.jpg', grayscale=False,
    color_mode='rgb')

img_test3 = tf.keras.preprocessing.image.load_img('drive/My Drive/DATA files/CNN model weights/Deer.jpg',
    grayscale=False,
    color_mode='rgb',
    target_size=(32,32))
img1 = np.array(img_test3)
img1.shape
img1 = img1 / 255.0
img1 = img1.reshape(1, 32, 32, 3)

result1 = np.argmax(load_model.predict(img1))
print(labels[result1])

image_test

plt.figure(figsize=(10,10))
plt.imshow(image_test)
plt.xlabel(labels[result1])
plt.show()